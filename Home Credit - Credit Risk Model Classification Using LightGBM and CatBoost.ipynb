{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit - Credit Risk Model Classification Using LightGBM and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the notebooks I created for Kaggle competitions: [Home Credit - Credit Risk Model Stability](https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability). \n",
    "\n",
    "The goal of this competition is to predict which clients are more likely to default on their loans using internal or external data sources that Home Credit has of clients, such as previous applications, bureau information and tax information. All the data are transformed and tokenized to protect the privacy of clients. The evaluation will favor solutions that are stable over time.\n",
    "\n",
    "I combined other public notebook with my own constructed features. With this and metric hacking (allowed by the competition host and the metric hacking part is not in this notebook), I achieved a rank of 25 in public leaderboard. \n",
    "Unfortunately, my feature engineering seemed to overfit the public leaderboard data and when it came to private leaderboard, my score dropped a lot. However, I think this is a very valuable experience for me. This is the first time I attended the Kaggle competition and I learned a lot of skills and knowledge from people contributed to this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from glob import glob\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from typing import Any\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ROOT = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n",
    "ROOT = Path(\"C:/Users/zyc71/Data Science Projects/Home Credit - Credit Risk Model Stability/home-credit-credit-risk-model-stability\")\n",
    "TRAIN_DIR = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR = ROOT / \"parquet_files\" / \"test\"\n",
    "\n",
    "# PERSONAL_PATH = '/kaggle/input/home-credit-feature-information/'\n",
    "PERSONAL_PATH = 'C:/Users/zyc71/Data Science Projects/Home Credit - Credit Risk Model Stability/'\n",
    "\n",
    "VERSION = str('_t60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for sum aggregation\n",
    "'''\n",
    "I reviewed the definition of each column and tried different feature constructions. \n",
    "\n",
    "The summation of the columns listed below is most useful. For example, debtoverdue_47A is the amount that is currently past due on a client's \n",
    "existing credit contract recorded in credit bureau. I sum up all past due amount of all contracts for each customer.\n",
    "\n",
    "Combining this feature construction and the metric hacking (which is allowed by the competition host), I can achieve 25th in the public leaderboard.\n",
    "However, this method seems to be overfitting the public data, when goes to private data, the score significantly drops.\n",
    "'''\n",
    "\n",
    "\n",
    "sum_cols = [\n",
    "    # applrev_1 \n",
    "    'applprev_1_net_dpd_D', 'annuity_853A', 'credacc_actualbalance_314A', 'credacc_credlmt_575A', 'credamount_590A', \n",
    "    'currdebt_94A', 'downpmt_134A', 'mainoccupationinc_437A', \t'outstandingdebt_522A', 'revolvingaccount_394A', \n",
    "    # tax_registry_a_1\n",
    "    'amount_4527230A',\n",
    "    # tax_registry_b_1\n",
    "    'amount_4917619A',\n",
    "    # tax_registry_c_1\n",
    "    'pmtamount_36A',\n",
    "    # credit_bureau_a_1\n",
    "    'credlmt_230A', 'credlmt_935A', 'debtoutstand_525A', 'debtoverdue_47A', 'instlamount_768A', 'instlamount_852A', \t\n",
    "    'monthlyinstlamount_332A', 'monthlyinstlamount_674A', 'outstandingamount_354A', 'outstandingamount_362A', 'overdueamount_31A', \n",
    "    'overdueamount_659A', 'residualamount_488A', 'residualamount_856A', 'totalamount_6A', 'totalamount_996A', 'totaldebtoverduevalue_178A',\n",
    "    'totaldebtoverduevalue_718A', 'totaloutstanddebtvalue_39A', 'totaloutstanddebtvalue_668A', \n",
    "    'contractsum_5085717L', 'numberofcontrsvalue_258L', 'numberofcontrsvalue_358L', 'numberofinstls_229L', 'numberofinstls_320L', \n",
    "    'numberofoutstandinstls_520L', 'numberofoutstandinstls_59L', 'numberofoverdueinstlmax_1039L', 'numberofoverdueinstlmax_1151L', \n",
    "    'numberofoverdueinstls_725L', 'numberofoverdueinstls_834L', 'prolongationcount_1120L', 'prolongationcount_599L', \n",
    "    # credit_bureau_b_1\n",
    "    'credlmt_1052A', 'credlmt_228A', 'credlmt_3940954A', 'debtpastduevalue_732A', 'debtvalue_227A', 'installmentamount_644A', \n",
    "    'installmentamount_833A', 'instlamount_892A', 'maxdebtpduevalodued_3940955A', 'overdueamountmax_950A', 'residualamount_1093A', \n",
    "    'residualamount_127A', 'residualamount_3940956A', 'totalamount_503A', 'totalamount_881A', \n",
    "    'credquantity_1099L', 'credquantity_984L', 'numberofinstls_810L', \t'pmtnumpending_403L', \n",
    "    # debitcard_1\n",
    "    'last180dayaveragebalance_704A', 'last180dayturnover_1134A', 'last30dayturnover_651A', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each feature ends with different characters, which indicates the type of that feature.\n",
    "# Define different aggregation functions for different types of features and also do summation for a list of features selected.\n",
    "class Aggregator:\n",
    "    \n",
    "    @staticmethod\n",
    "    def max_expr(df):\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating maximum values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for maximum values.\n",
    "        \"\"\"\n",
    "        cols = [\n",
    "            col\n",
    "            for col in df.columns\n",
    "            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n",
    "        ]\n",
    "\n",
    "        expr_max = [\n",
    "            pl.col(col).max().alias(f\"max_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def min_expr(df):\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating minimum values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for minimum values.\n",
    "        \"\"\"\n",
    "        cols = [\n",
    "            col\n",
    "            for col in df.columns\n",
    "            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n",
    "        ]\n",
    "\n",
    "        expr_min = [\n",
    "            pl.col(col).min().alias(f\"min_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_min\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_expr(df):\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating mean values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for mean values.\n",
    "        \"\"\"\n",
    "        cols = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n",
    "\n",
    "        expr_mean = [\n",
    "            pl.col(col).mean().alias(f\"mean_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_mean\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def var_expr(df):\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating variance for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for variance.\n",
    "        \"\"\"\n",
    "        cols = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n",
    "\n",
    "        expr_mean = [\n",
    "            pl.col(col).var().alias(f\"var_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_mean\n",
    "\n",
    "    @staticmethod\n",
    "    def mode_expr(df):\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating mode values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for mode values.\n",
    "        \"\"\"\n",
    "        cols = [col for col in df.columns if col.endswith(\"M\")]\n",
    "\n",
    "        expr_mode = [\n",
    "            pl.col(col).drop_nulls().mode().first().alias(f\"mode_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_mode\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def sum_expr(df):\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating maximum values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for sum values.\n",
    "        \"\"\"\n",
    "        cols = [\n",
    "            col\n",
    "            for col in df.columns\n",
    "            if col in sum_cols\n",
    "        ]\n",
    "\n",
    "        expr_sum = [\n",
    "            pl.col(col).sum().alias(f\"sum_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_sum\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_exprs(df):\n",
    "        \"\"\"\n",
    "        Combines expressions for maximum, mean, and variance calculations.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of combined expressions.\n",
    "        \"\"\"\n",
    "        exprs = (\n",
    "            Aggregator.max_expr(df) + Aggregator.mean_expr(df) + Aggregator.var_expr(df) + Aggregator.sum_expr(df)\n",
    "        )\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utility:\n",
    "\n",
    "    @staticmethod\n",
    "    # Kaggle has limited memory, use this function to optimize memory usage\n",
    "    def reduce_memory_usage(df, name):\n",
    "        \"\"\"\n",
    "        Reduces memory usage of a DataFrame by converting column types.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.DataFrame): DataFrame to optimize.\n",
    "        - name (str): Name of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Optimized DataFrame.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n",
    "        )\n",
    "\n",
    "        int_types = [\n",
    "            pl.Int8,\n",
    "            pl.Int16,\n",
    "            pl.Int32,\n",
    "            pl.Int64,\n",
    "            pl.UInt8,\n",
    "            pl.UInt16,\n",
    "            pl.UInt32,\n",
    "            pl.UInt64,\n",
    "        ]\n",
    "        float_types = [pl.Float32, pl.Float64]\n",
    "\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "            if col_type in int_types + float_types:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if c_min is not None and c_max is not None:\n",
    "                    if col_type in int_types:\n",
    "                        if c_min >= 0:\n",
    "                            if (\n",
    "                                c_min >= np.iinfo(np.uint8).min\n",
    "                                and c_max <= np.iinfo(np.uint8).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt8))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint16).min\n",
    "                                and c_max <= np.iinfo(np.uint16).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt16))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint32).min\n",
    "                                and c_max <= np.iinfo(np.uint32).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt32))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint64).min\n",
    "                                and c_max <= np.iinfo(np.uint64).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt64))\n",
    "                        else:\n",
    "                            if (\n",
    "                                c_min >= np.iinfo(np.int8).min\n",
    "                                and c_max <= np.iinfo(np.int8).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int8))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int16).min\n",
    "                                and c_max <= np.iinfo(np.int16).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int16))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int32).min\n",
    "                                and c_max <= np.iinfo(np.int32).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int32))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int64).min\n",
    "                                and c_max <= np.iinfo(np.int64).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int64))\n",
    "                    elif col_type in float_types:\n",
    "                        if (\n",
    "                            c_min > np.finfo(np.float32).min\n",
    "                            and c_max < np.finfo(np.float32).max\n",
    "                        ):\n",
    "                            df = df.with_columns(df[col].cast(pl.Float32))\n",
    "\n",
    "        print(\n",
    "            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_pandas(df, cat_cols = None):\n",
    "        \"\"\"\n",
    "        Converts a Polars DataFrame to a Pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.DataFrame): Polars DataFrame to convert.\n",
    "        - cat_cols (list[str]): List of categorical columns. Default is None.\n",
    "\n",
    "        Returns:\n",
    "        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n",
    "        \"\"\"\n",
    "        df = df.to_pandas()\n",
    "\n",
    "        if cat_cols is None:\n",
    "            cat_cols = list(df.select_dtypes(\"object\").columns)\n",
    "\n",
    "        df[cat_cols] = df[cat_cols].astype(\"str\")\n",
    "\n",
    "        return df, cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaGen:\n",
    "    \n",
    "    @staticmethod\n",
    "    # Cast data types\n",
    "    def change_dtypes(df):\n",
    "        \"\"\"\n",
    "        Changes the data types of columns in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pl.LazyFrame: LazyFrame with modified data types.\n",
    "        \"\"\"\n",
    "        for col in df.columns:\n",
    "            if col == \"case_id\":\n",
    "                df = df.with_columns(pl.col(col).cast(pl.UInt32).alias(col))\n",
    "            elif col in [\"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.UInt16).alias(col))\n",
    "            elif col == \"date_decision\" or col[-1] == \"D\":\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date).alias(col))\n",
    "            elif col[-1] in [\"P\", \"A\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "        return df\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    # Scan each data file, complete aggregation and concatenate all the results (one data source may have more than one data file)\n",
    "    def scan_files(glob_path, depth = None):\n",
    "        \"\"\"\n",
    "        Scans Parquet files matching the glob pattern and combines them into a LazyFrame.\n",
    "\n",
    "        Args:\n",
    "        - glob_path (str): Glob pattern to match Parquet files.\n",
    "        - depth (int, optional): Depth level for data aggregation. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        - pl.LazyFrame: Combined LazyFrame.\n",
    "        \"\"\"\n",
    "        chunks: list[pl.LazyFrame] = []\n",
    "        for path in glob(str(glob_path)):\n",
    "            df: pl.LazyFrame = pl.scan_parquet(\n",
    "                path, low_memory = True, rechunk = True\n",
    "            ).pipe(SchemaGen.change_dtypes)\n",
    "            print(f\"File {Path(path).stem} loaded into memory.\")\n",
    "\n",
    "            if depth in (1, 2):\n",
    "                exprs = Aggregator.get_exprs(df)\n",
    "                df = df.group_by(\"case_id\").agg(exprs)\n",
    "\n",
    "                del exprs\n",
    "                gc.collect()\n",
    "\n",
    "            chunks.append(df)\n",
    "\n",
    "        df = pl.concat(chunks, how = \"vertical_relaxed\")\n",
    "\n",
    "        del chunks\n",
    "        gc.collect()\n",
    "\n",
    "        df = df.unique(subset=[\"case_id\"])\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    # Join all data into one data frame\n",
    "    def join_dataframes(\n",
    "        df_base,\n",
    "        depth_0,\n",
    "        depth_1,\n",
    "        depth_2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Joins multiple LazyFrames with a base LazyFrame.\n",
    "\n",
    "        Args:\n",
    "        - df_base (pl.LazyFrame): Base LazyFrame.\n",
    "        - depth_0 (list[pl.LazyFrame]): List of LazyFrames for depth 0.\n",
    "        - depth_1 (list[pl.LazyFrame]): List of LazyFrames for depth 1.\n",
    "        - depth_2 (list[pl.LazyFrame]): List of LazyFrames for depth 2.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Joined DataFrame.\n",
    "        \"\"\"\n",
    "        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "            df_base = df_base.join(df, how = \"left\", on = \"case_id\", suffix = f\"_{i}\")\n",
    "\n",
    "        return df_base.collect().pipe(Utility.reduce_memory_usage, \"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out some features with too many missing values, too many unique values or only one possible value\n",
    "def filter_cols(df):\n",
    "    \"\"\"\n",
    "    Filters columns in the DataFrame based on null percentage and unique values for string columns.\n",
    "\n",
    "    Args:\n",
    "    - df (pl.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: DataFrame with filtered columns.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]:\n",
    "            null_pct = df[col].is_null().mean()\n",
    "\n",
    "            if null_pct > 0.95:\n",
    "                df = df.drop(col)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]) & (\n",
    "            df[col].dtype == pl.String\n",
    "        ):\n",
    "            freq = df[col].n_unique()\n",
    "\n",
    "            if (freq > 200) | (freq == 1):\n",
    "                df = df.drop(col)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# riskassesment_302T feature has values like \"8% - 11%\", transform this feature into a range and average\n",
    "def transform_cols(df):\n",
    "    \"\"\"\n",
    "    Transforms columns in the DataFrame according to predefined rules.\n",
    "\n",
    "    Args:\n",
    "    - df (pl.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: DataFrame with transformed columns.\n",
    "    \"\"\"\n",
    "    if \"riskassesment_302T\" in df.columns:\n",
    "        if df[\"riskassesment_302T\"].dtype == pl.Null:\n",
    "            df = df.with_columns(\n",
    "                [\n",
    "                    pl.Series(\n",
    "                        \"riskassesment_302T_rng\", df[\"riskassesment_302T\"], pl.UInt8\n",
    "                    ),\n",
    "                    pl.Series(\n",
    "                        \"riskassesment_302T_mean\", df[\"riskassesment_302T\"], pl.UInt8\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            pct_low = (\n",
    "                df[\"riskassesment_302T\"]\n",
    "                .str.split(\" - \")\n",
    "                .apply(lambda x: x[0].replace(\"%\", \"\"))\n",
    "                .cast(pl.UInt8)\n",
    "            )\n",
    "            pct_high = (\n",
    "                df[\"riskassesment_302T\"]\n",
    "                .str.split(\" - \")\n",
    "                .apply(lambda x: x[1].replace(\"%\", \"\"))\n",
    "                .cast(pl.UInt8)\n",
    "            )\n",
    "\n",
    "            diff = pct_high - pct_low\n",
    "            avg = ((pct_low + pct_high) / 2).cast(pl.Float32)\n",
    "\n",
    "            del pct_high, pct_low\n",
    "            gc.collect()\n",
    "\n",
    "            df = df.with_columns(\n",
    "                [\n",
    "                    diff.alias(\"riskassesment_302T_rng\"),\n",
    "                    avg.alias(\"riskassesment_302T_mean\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        df.drop(\"riskassesment_302T\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# For each datetime feature (already aggregated), calculate the difference between it and decision date.\n",
    "# In addition, convert the decision date into year and day of month\n",
    "def handle_dates(df):\n",
    "    \"\"\"\n",
    "    Handles date columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pl.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: DataFrame with transformed date columns.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col.endswith(\"D\"):\n",
    "            df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "            df = df.with_columns(pl.col(col).dt.total_days().cast(pl.Int32))\n",
    "\n",
    "    df = df.rename(\n",
    "        {\n",
    "            \"MONTH\": \"month\",\n",
    "            \"WEEK_NUM\": \"week_num\"\n",
    "        }\n",
    "    )\n",
    "            \n",
    "    df = df.with_columns(\n",
    "        [\n",
    "            pl.col(\"date_decision\").dt.year().alias(\"year\").cast(pl.Int16),\n",
    "            pl.col(\"date_decision\").dt.day().alias(\"day\").cast(pl.UInt8),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return df.drop(\"date_decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File train_base loaded into memory.\n",
      "File train_static_cb_0 loaded into memory.\n",
      "File train_static_0_0 loaded into memory.\n",
      "File train_static_0_1 loaded into memory.\n",
      "File train_applprev_1_0 loaded into memory.\n",
      "File train_applprev_1_1 loaded into memory.\n",
      "File train_tax_registry_a_1 loaded into memory.\n",
      "File train_tax_registry_b_1 loaded into memory.\n",
      "File train_tax_registry_c_1 loaded into memory.\n",
      "File train_credit_bureau_a_1_0 loaded into memory.\n",
      "File train_credit_bureau_a_1_1 loaded into memory.\n",
      "File train_credit_bureau_a_1_2 loaded into memory.\n",
      "File train_credit_bureau_a_1_3 loaded into memory.\n",
      "File train_credit_bureau_b_1 loaded into memory.\n",
      "File train_other_1 loaded into memory.\n",
      "File train_person_1 loaded into memory.\n",
      "File train_deposit_1 loaded into memory.\n",
      "File train_debitcard_1 loaded into memory.\n",
      "File train_credit_bureau_a_2_0 loaded into memory.\n",
      "File train_credit_bureau_a_2_1 loaded into memory.\n",
      "File train_credit_bureau_a_2_10 loaded into memory.\n",
      "File train_credit_bureau_a_2_2 loaded into memory.\n",
      "File train_credit_bureau_a_2_3 loaded into memory.\n",
      "File train_credit_bureau_a_2_4 loaded into memory.\n",
      "File train_credit_bureau_a_2_5 loaded into memory.\n",
      "File train_credit_bureau_a_2_6 loaded into memory.\n",
      "File train_credit_bureau_a_2_7 loaded into memory.\n",
      "File train_credit_bureau_a_2_8 loaded into memory.\n",
      "File train_credit_bureau_a_2_9 loaded into memory.\n",
      "File train_credit_bureau_b_2 loaded into memory.\n",
      "Memory usage of dataframe \"df_train\" is 7575.7066 MB.\n",
      "Memory usage of dataframe \"df_train\" became 4576.4795 MB.\n",
      "Memory usage of dataframe \"df_train\" is 3159.1924 MB.\n",
      "Memory usage of dataframe \"df_train\" became 2953.9054 MB.\n",
      "Train data shape: (1526659, 520)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 520)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>month</th><th>week_num</th><th>target</th><th>assignmentdate_238D</th><th>assignmentdate_4527235D</th><th>birthdate_574D</th><th>contractssum_5085716L</th><th>dateofbirth_337D</th><th>days120_123L</th><th>days180_256L</th><th>days30_165L</th><th>days360_512L</th><th>days90_310L</th><th>description_5085714M</th><th>education_1103M</th><th>education_88M</th><th>firstquarter_103L</th><th>fourthquarter_440L</th><th>maritalst_385M</th><th>maritalst_893M</th><th>numberofqueries_373L</th><th>pmtaverage_3A</th><th>pmtaverage_4527227A</th><th>pmtcount_4527229L</th><th>pmtcount_693L</th><th>pmtscount_423L</th><th>pmtssum_45A</th><th>requesttype_4525192L</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>secondquarter_766L</th><th>thirdquarter_1082L</th><th>actualdpdtolerance_344P</th><th>amtinstpaidbefduel24m_4187115A</th><th>annuity_780A</th><th>&hellip;</th><th>max_openingdate_313D</th><th>mean_amount_416A</th><th>mean_openingdate_313D</th><th>max_num_group1_11</th><th>max_openingdate_857D</th><th>mean_openingdate_857D</th><th>sum_last180dayaveragebalance_704A</th><th>sum_last180dayturnover_1134A</th><th>sum_last30dayturnover_651A</th><th>max_collater_typofvalofguarant_298M</th><th>max_collater_typofvalofguarant_407M</th><th>max_collater_valueofguarantee_1124L</th><th>max_collater_valueofguarantee_876L</th><th>max_collaterals_typeofguarante_359M</th><th>max_collaterals_typeofguarante_669M</th><th>max_num_group1_12</th><th>max_num_group2</th><th>max_pmts_dpd_1073P</th><th>max_pmts_dpd_303P</th><th>max_pmts_month_158T</th><th>max_pmts_month_706T</th><th>max_pmts_overdue_1140A</th><th>max_pmts_overdue_1152A</th><th>max_pmts_year_1139T</th><th>max_pmts_year_507T</th><th>max_subjectroles_name_541M</th><th>max_subjectroles_name_838M</th><th>mean_pmts_dpd_1073P</th><th>mean_pmts_dpd_303P</th><th>mean_pmts_overdue_1140A</th><th>mean_pmts_overdue_1152A</th><th>var_pmts_dpd_1073P</th><th>var_pmts_dpd_303P</th><th>var_pmts_overdue_1140A</th><th>var_pmts_overdue_1152A</th><th>year</th><th>day</th></tr><tr><td>u32</td><td>u32</td><td>u8</td><td>u8</td><td>i16</td><td>u8</td><td>i16</td><td>f32</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>i8</td><td>u8</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>i16</td><td>f32</td><td>i16</td><td>u8</td><td>i16</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>u16</td><td>u8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>u16</td><td>u8</td></tr></thead><tbody><tr><td>1574279</td><td>201910</td><td>40</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-12580</td><td>2.0</td><td>2.0</td><td>2.0</td><td>7.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>9.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>7.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>1.0</td><td>2.0</td><td>0.0</td><td>18897.158203</td><td>2429.400146</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>35</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2020.0</td><td>2019.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2019</td><td>10</td></tr><tr><td>1580043</td><td>201910</td><td>40</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-11091</td><td>3.0</td><td>4.0</td><td>0.0</td><td>6.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>8.0</td><td>5.0</td><td>&quot;a7fcb6e5&quot;</td><td>&quot;a55475b1&quot;</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>9.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>3153.400146</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>9</td><td>35</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2019</td><td>13</td></tr><tr><td>1587909</td><td>201910</td><td>41</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-11614</td><td>3.0</td><td>3.0</td><td>2.0</td><td>9.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>7.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>9.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>2.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>9822.600586</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>1</td><td>35</td><td>21.0</td><td>33.0</td><td>12.0</td><td>12.0</td><td>31887.4375</td><td>9720.662109</td><td>2020.0</td><td>2019.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>1.636364</td><td>6.157895</td><td>3901.07959</td><td>2690.657959</td><td>21.051136</td><td>67.704124</td><td>1.08703648e8</td><td>8.961506e6</td><td>2019</td><td>19</td></tr><tr><td>1303197</td><td>201903</td><td>9</td><td>0</td><td>null</td><td>null</td><td>-20216</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>5230.200195</td><td>null</td><td>14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>2175.800049</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019</td><td>8</td></tr><tr><td>1612159</td><td>201911</td><td>43</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-12148</td><td>1.0</td><td>2.0</td><td>1.0</td><td>4.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>6.0</td><td>4.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>4.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>0.0</td><td>1.0</td><td>0.0</td><td>126995.0</td><td>13333.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>6.3375e6</td><td>219990.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>3</td><td>35</td><td>2.0</td><td>4.0</td><td>12.0</td><td>12.0</td><td>39502.109375</td><td>3186.573975</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.107143</td><td>0.068966</td><td>2819.629883</td><td>54.940929</td><td>0.17328</td><td>0.275862</td><td>1.07182048e8</td><td>175073.34375</td><td>2019</td><td>4</td></tr><tr><td>1671541</td><td>201912</td><td>48</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-12911</td><td>1.0</td><td>2.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>2.0</td><td>0.0</td><td>0.0</td><td>10645.600586</td><td>1741.400024</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>23</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2019</td><td>7</td></tr><tr><td>1748480</td><td>202001</td><td>54</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-13680</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>10198.0</td><td>1376.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>11</td><td>6.0</td><td>null</td><td>12.0</td><td>null</td><td>16.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>1.0</td><td>null</td><td>2.666667</td><td>null</td><td>6.0</td><td>null</td><td>42.666668</td><td>null</td><td>2020</td><td>14</td></tr><tr><td>1863564</td><td>202006</td><td>75</td><td>0</td><td>null</td><td>null</td><td>null</td><td>168005.546875</td><td>-8446</td><td>2.0</td><td>4.0</td><td>0.0</td><td>8.0</td><td>1.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>3.0</td><td>&quot;a7fcb6e5&quot;</td><td>&quot;a55475b1&quot;</td><td>8.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>2.0</td><td>1.0</td><td>0.0</td><td>29976.0</td><td>3662.800049</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>3</td><td>23</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2020</td><td>15</td></tr><tr><td>1932521</td><td>202009</td><td>89</td><td>0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>-20471</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>3.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>5.0</td><td>3.0</td><td>0.0</td><td>90076.710938</td><td>2753.199951</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>9.272e6</td><td>105000.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>6</td><td>35</td><td>0.0</td><td>1150.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>51958.601562</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;daf49a8a&quot;</td><td>0.0</td><td>318.879303</td><td>0.0</td><td>16760.066406</td><td>0.0</td><td>180322.03125</td><td>0.0</td><td>4.49149376e8</td><td>2020</td><td>18</td></tr><tr><td>2585425</td><td>201906</td><td>23</td><td>0</td><td>null</td><td>null</td><td>-10608</td><td>null</td><td>-10608</td><td>5.0</td><td>7.0</td><td>3.0</td><td>14.0</td><td>4.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>13.0</td><td>6.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>14.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>7.0</td><td>8037.5</td><td>null</td><td>14</td><td>null</td><td>null</td><td>7.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>8225.200195</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>4</td><td>35</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2019</td><td>17</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 520)\n",
       "┌─────────┬────────┬──────────┬────────┬───┬────────────────────────┬────────────────────────┬──────┬─────┐\n",
       "│ case_id ┆ month  ┆ week_num ┆ target ┆ … ┆ var_pmts_overdue_1140A ┆ var_pmts_overdue_1152A ┆ year ┆ day │\n",
       "│ ---     ┆ ---    ┆ ---      ┆ ---    ┆   ┆ ---                    ┆ ---                    ┆ ---  ┆ --- │\n",
       "│ u32     ┆ u32    ┆ u8       ┆ u8     ┆   ┆ f32                    ┆ f32                    ┆ u16  ┆ u8  │\n",
       "╞═════════╪════════╪══════════╪════════╪═══╪════════════════════════╪════════════════════════╪══════╪═════╡\n",
       "│ 1574279 ┆ 201910 ┆ 40       ┆ 0      ┆ … ┆ 0.0                    ┆ 0.0                    ┆ 2019 ┆ 10  │\n",
       "│ 1580043 ┆ 201910 ┆ 40       ┆ 0      ┆ … ┆ 0.0                    ┆ 0.0                    ┆ 2019 ┆ 13  │\n",
       "│ 1587909 ┆ 201910 ┆ 41       ┆ 0      ┆ … ┆ 1.08703648e8           ┆ 8.961506e6             ┆ 2019 ┆ 19  │\n",
       "│ 1303197 ┆ 201903 ┆ 9        ┆ 0      ┆ … ┆ null                   ┆ null                   ┆ 2019 ┆ 8   │\n",
       "│ 1612159 ┆ 201911 ┆ 43       ┆ 0      ┆ … ┆ 1.07182048e8           ┆ 175073.34375           ┆ 2019 ┆ 4   │\n",
       "│ 1671541 ┆ 201912 ┆ 48       ┆ 0      ┆ … ┆ 0.0                    ┆ 0.0                    ┆ 2019 ┆ 7   │\n",
       "│ 1748480 ┆ 202001 ┆ 54       ┆ 0      ┆ … ┆ 42.666668              ┆ null                   ┆ 2020 ┆ 14  │\n",
       "│ 1863564 ┆ 202006 ┆ 75       ┆ 0      ┆ … ┆ 0.0                    ┆ 0.0                    ┆ 2020 ┆ 15  │\n",
       "│ 1932521 ┆ 202009 ┆ 89       ┆ 0      ┆ … ┆ 0.0                    ┆ 4.49149376e8           ┆ 2020 ┆ 18  │\n",
       "│ 2585425 ┆ 201906 ┆ 23       ┆ 0      ┆ … ┆ 0.0                    ┆ 0.0                    ┆ 2019 ┆ 17  │\n",
       "└─────────┴────────┴──────────┴────────┴───┴────────────────────────┴────────────────────────┴──────┴─────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use UDFs above to scan all training parquet files and process\n",
    "\n",
    "data_store = {\n",
    "    \"df_base\": SchemaGen.scan_files(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_train = (\n",
    "    SchemaGen.join_dataframes(**data_store)\n",
    "    .pipe(filter_cols)\n",
    "    .pipe(transform_cols)\n",
    "    .pipe(handle_dates)\n",
    "    .pipe(Utility.reduce_memory_usage, \"df_train\")\n",
    ")\n",
    "\n",
    "del data_store\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Train data shape: {df_train.shape}\")\n",
    "display(df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_base loaded into memory.\n",
      "File test_static_cb_0 loaded into memory.\n",
      "File test_static_0_0 loaded into memory.\n",
      "File test_static_0_1 loaded into memory.\n",
      "File test_static_0_2 loaded into memory.\n",
      "File test_applprev_1_0 loaded into memory.\n",
      "File test_applprev_1_1 loaded into memory.\n",
      "File test_applprev_1_2 loaded into memory.\n",
      "File test_tax_registry_a_1 loaded into memory.\n",
      "File test_tax_registry_b_1 loaded into memory.\n",
      "File test_tax_registry_c_1 loaded into memory.\n",
      "File test_credit_bureau_a_1_0 loaded into memory.\n",
      "File test_credit_bureau_a_1_1 loaded into memory.\n",
      "File test_credit_bureau_a_1_2 loaded into memory.\n",
      "File test_credit_bureau_a_1_3 loaded into memory.\n",
      "File test_credit_bureau_a_1_4 loaded into memory.\n",
      "File test_credit_bureau_b_1 loaded into memory.\n",
      "File test_other_1 loaded into memory.\n",
      "File test_person_1 loaded into memory.\n",
      "File test_deposit_1 loaded into memory.\n",
      "File test_debitcard_1 loaded into memory.\n",
      "File test_credit_bureau_a_2_0 loaded into memory.\n",
      "File test_credit_bureau_a_2_1 loaded into memory.\n",
      "File test_credit_bureau_a_2_10 loaded into memory.\n",
      "File test_credit_bureau_a_2_11 loaded into memory.\n",
      "File test_credit_bureau_a_2_2 loaded into memory.\n",
      "File test_credit_bureau_a_2_3 loaded into memory.\n",
      "File test_credit_bureau_a_2_4 loaded into memory.\n",
      "File test_credit_bureau_a_2_5 loaded into memory.\n",
      "File test_credit_bureau_a_2_6 loaded into memory.\n",
      "File test_credit_bureau_a_2_7 loaded into memory.\n",
      "File test_credit_bureau_a_2_8 loaded into memory.\n",
      "File test_credit_bureau_a_2_9 loaded into memory.\n",
      "File test_credit_bureau_b_2 loaded into memory.\n",
      "Memory usage of dataframe \"df_train\" is 0.0484 MB.\n",
      "Memory usage of dataframe \"df_train\" became 0.0347 MB.\n",
      "Memory usage of dataframe \"df_test\" is 0.0205 MB.\n",
      "Memory usage of dataframe \"df_test\" became 0.0194 MB.\n",
      "Test data shape: (10, 519)\n"
     ]
    }
   ],
   "source": [
    "# Use UDFs above to scan all test parquet files and process\n",
    "\n",
    "data_store = {\n",
    "    \"df_base\": SchemaGen.scan_files(TEST_DIR / \"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_test = (\n",
    "    SchemaGen.join_dataframes(**data_store)\n",
    "    .pipe(transform_cols)\n",
    "    .pipe(handle_dates)\n",
    "    .select([col for col in df_train.columns if col != \"target\"])\n",
    "    .pipe(Utility.reduce_memory_usage, \"df_test\")\n",
    ")\n",
    "\n",
    "del data_store\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Test data shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polars data frame to pandas data frame\n",
    "\n",
    "df_train, cat_cols = Utility.to_pandas(df_train)\n",
    "df_test, cat_cols = Utility.to_pandas(df_test, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions for further ensemble learning use\n",
    "\n",
    "class VotingModel(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A voting ensemble model that combines predictions from multiple estimators.\n",
    "\n",
    "    Parameters:\n",
    "    - estimators (list): List of base estimators.\n",
    "\n",
    "    Attributes:\n",
    "    - estimators (list): List of base estimators.\n",
    "\n",
    "    Methods:\n",
    "    - fit(X, y=None): Fit the model to the training data.\n",
    "    - predict(X): Predict class labels for samples.\n",
    "    - predict_proba(X): Predict class probabilities for samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators):\n",
    "        \"\"\"\n",
    "        Initialize the VotingModel with a list of base estimators.\n",
    "\n",
    "        Args:\n",
    "        - estimators (list): List of base estimators.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "        - y: Target labels (ignored).\n",
    "\n",
    "        Returns:\n",
    "        - self: Returns the instance itself.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Predicted class labels.\n",
    "        \"\"\"\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for samples.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Predicted class probabilities.\n",
    "        \"\"\"\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6735594\tbest: 0.6735594 (0)\ttotal: 198ms\tremaining: 19m 47s\n",
      "300:\ttest: 0.8488633\tbest: 0.8488633 (300)\ttotal: 59.6s\tremaining: 18m 47s\n",
      "600:\ttest: 0.8541675\tbest: 0.8541675 (600)\ttotal: 1m 58s\tremaining: 17m 41s\n",
      "900:\ttest: 0.8565263\tbest: 0.8565263 (900)\ttotal: 2m 56s\tremaining: 16m 39s\n",
      "1200:\ttest: 0.8581834\tbest: 0.8581834 (1200)\ttotal: 3m 55s\tremaining: 15m 39s\n",
      "1500:\ttest: 0.8591421\tbest: 0.8591421 (1500)\ttotal: 4m 53s\tremaining: 14m 39s\n",
      "1800:\ttest: 0.8600221\tbest: 0.8600221 (1800)\ttotal: 5m 51s\tremaining: 13m 39s\n",
      "2100:\ttest: 0.8606563\tbest: 0.8606563 (2100)\ttotal: 6m 50s\tremaining: 12m 40s\n",
      "2400:\ttest: 0.8612165\tbest: 0.8612165 (2400)\ttotal: 7m 48s\tremaining: 11m 42s\n",
      "2700:\ttest: 0.8617208\tbest: 0.8617208 (2700)\ttotal: 8m 47s\tremaining: 10m 44s\n",
      "3000:\ttest: 0.8621022\tbest: 0.8621038 (2975)\ttotal: 9m 46s\tremaining: 9m 45s\n",
      "3300:\ttest: 0.8624181\tbest: 0.8624243 (3270)\ttotal: 10m 44s\tremaining: 8m 47s\n",
      "3600:\ttest: 0.8626831\tbest: 0.8626831 (3600)\ttotal: 11m 42s\tremaining: 7m 48s\n",
      "3900:\ttest: 0.8629304\tbest: 0.8629304 (3900)\ttotal: 12m 40s\tremaining: 6m 49s\n",
      "4200:\ttest: 0.8632497\tbest: 0.8632497 (4200)\ttotal: 13m 39s\tremaining: 5m 50s\n",
      "4500:\ttest: 0.8634768\tbest: 0.8634768 (4500)\ttotal: 14m 38s\tremaining: 4m 52s\n",
      "4800:\ttest: 0.8636538\tbest: 0.8636538 (4800)\ttotal: 15m 36s\tremaining: 3m 53s\n",
      "5100:\ttest: 0.8638591\tbest: 0.8638591 (5100)\ttotal: 16m 34s\tremaining: 2m 55s\n",
      "5400:\ttest: 0.8640019\tbest: 0.8640019 (5400)\ttotal: 17m 33s\tremaining: 1m 56s\n",
      "5700:\ttest: 0.8641819\tbest: 0.8641840 (5690)\ttotal: 18m 32s\tremaining: 58.3s\n",
      "5999:\ttest: 0.8643125\tbest: 0.8643163 (5995)\ttotal: 19m 30s\tremaining: 0us\n",
      "bestTest = 0.8643162847\n",
      "bestIteration = 5995\n",
      "Shrink model to first 5996 iterations.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.848867\n",
      "[200]\tvalid_0's auc: 0.858235\n",
      "[300]\tvalid_0's auc: 0.861562\n",
      "[400]\tvalid_0's auc: 0.863001\n",
      "[500]\tvalid_0's auc: 0.863368\n",
      "[600]\tvalid_0's auc: 0.863603\n",
      "[700]\tvalid_0's auc: 0.863838\n",
      "[800]\tvalid_0's auc: 0.863932\n",
      "[900]\tvalid_0's auc: 0.864045\n",
      "[1000]\tvalid_0's auc: 0.863993\n",
      "Early stopping, best iteration is:\n",
      "[905]\tvalid_0's auc: 0.864084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6833925\tbest: 0.6833925 (0)\ttotal: 388ms\tremaining: 38m 49s\n",
      "300:\ttest: 0.8379942\tbest: 0.8379942 (300)\ttotal: 1m\tremaining: 19m 9s\n",
      "600:\ttest: 0.8431437\tbest: 0.8431437 (600)\ttotal: 2m 1s\tremaining: 18m 8s\n",
      "900:\ttest: 0.8453843\tbest: 0.8453843 (900)\ttotal: 3m 2s\tremaining: 17m 14s\n",
      "1200:\ttest: 0.8465820\tbest: 0.8465820 (1200)\ttotal: 4m 2s\tremaining: 16m 10s\n",
      "1500:\ttest: 0.8477875\tbest: 0.8477875 (1500)\ttotal: 5m 2s\tremaining: 15m 5s\n",
      "1800:\ttest: 0.8486117\tbest: 0.8486117 (1800)\ttotal: 6m 1s\tremaining: 14m 3s\n",
      "2100:\ttest: 0.8492302\tbest: 0.8492397 (2095)\ttotal: 7m 1s\tremaining: 13m 2s\n",
      "2400:\ttest: 0.8497553\tbest: 0.8497553 (2400)\ttotal: 8m 2s\tremaining: 12m 2s\n",
      "2700:\ttest: 0.8501998\tbest: 0.8501998 (2700)\ttotal: 9m 2s\tremaining: 11m 2s\n",
      "3000:\ttest: 0.8506450\tbest: 0.8506450 (3000)\ttotal: 10m 1s\tremaining: 10m 1s\n",
      "3300:\ttest: 0.8509005\tbest: 0.8509005 (3300)\ttotal: 11m 2s\tremaining: 9m 1s\n",
      "3600:\ttest: 0.8512725\tbest: 0.8512725 (3600)\ttotal: 12m\tremaining: 7m 59s\n",
      "3900:\ttest: 0.8515257\tbest: 0.8515257 (3900)\ttotal: 12m 58s\tremaining: 6m 59s\n",
      "4200:\ttest: 0.8517981\tbest: 0.8517981 (4200)\ttotal: 13m 58s\tremaining: 5m 58s\n",
      "4500:\ttest: 0.8520291\tbest: 0.8520343 (4480)\ttotal: 14m 58s\tremaining: 4m 59s\n",
      "4800:\ttest: 0.8523024\tbest: 0.8523040 (4795)\ttotal: 16m\tremaining: 3m 59s\n",
      "5100:\ttest: 0.8525167\tbest: 0.8525167 (5100)\ttotal: 17m 1s\tremaining: 3m\n",
      "5400:\ttest: 0.8526744\tbest: 0.8526797 (5320)\ttotal: 18m 3s\tremaining: 2m\n",
      "5700:\ttest: 0.8527833\tbest: 0.8527843 (5695)\ttotal: 19m 3s\tremaining: 60s\n",
      "5999:\ttest: 0.8529277\tbest: 0.8529283 (5995)\ttotal: 20m 1s\tremaining: 0us\n",
      "bestTest = 0.8529282808\n",
      "bestIteration = 5995\n",
      "Shrink model to first 5996 iterations.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830534\n",
      "[200]\tvalid_0's auc: 0.842075\n",
      "[300]\tvalid_0's auc: 0.846693\n",
      "[400]\tvalid_0's auc: 0.849122\n",
      "[500]\tvalid_0's auc: 0.850628\n",
      "[600]\tvalid_0's auc: 0.851507\n",
      "[700]\tvalid_0's auc: 0.85191\n",
      "[800]\tvalid_0's auc: 0.852221\n",
      "[900]\tvalid_0's auc: 0.852422\n",
      "[1000]\tvalid_0's auc: 0.852701\n",
      "[1100]\tvalid_0's auc: 0.852869\n",
      "[1200]\tvalid_0's auc: 0.853089\n",
      "[1300]\tvalid_0's auc: 0.853088\n",
      "[1400]\tvalid_0's auc: 0.853148\n",
      "[1500]\tvalid_0's auc: 0.85327\n",
      "[1600]\tvalid_0's auc: 0.853378\n",
      "[1700]\tvalid_0's auc: 0.853466\n",
      "[1800]\tvalid_0's auc: 0.853489\n",
      "[1900]\tvalid_0's auc: 0.853599\n",
      "[2000]\tvalid_0's auc: 0.853637\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1964]\tvalid_0's auc: 0.853698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6597642\tbest: 0.6597642 (0)\ttotal: 485ms\tremaining: 48m 26s\n",
      "300:\ttest: 0.8438950\tbest: 0.8438950 (300)\ttotal: 1m\tremaining: 19m 10s\n",
      "600:\ttest: 0.8487698\tbest: 0.8487698 (600)\ttotal: 2m\tremaining: 18m 3s\n",
      "900:\ttest: 0.8507326\tbest: 0.8507326 (900)\ttotal: 3m\tremaining: 16m 58s\n",
      "1200:\ttest: 0.8519702\tbest: 0.8519702 (1200)\ttotal: 4m\tremaining: 15m 59s\n",
      "1500:\ttest: 0.8529012\tbest: 0.8529012 (1500)\ttotal: 5m 1s\tremaining: 15m 4s\n",
      "1800:\ttest: 0.8536661\tbest: 0.8536661 (1800)\ttotal: 6m 2s\tremaining: 14m 5s\n",
      "2100:\ttest: 0.8541255\tbest: 0.8541255 (2100)\ttotal: 7m 2s\tremaining: 13m 4s\n",
      "2400:\ttest: 0.8546107\tbest: 0.8546107 (2400)\ttotal: 8m 2s\tremaining: 12m 3s\n",
      "2700:\ttest: 0.8549064\tbest: 0.8549064 (2700)\ttotal: 9m 2s\tremaining: 11m 2s\n",
      "3000:\ttest: 0.8551682\tbest: 0.8551682 (3000)\ttotal: 10m 2s\tremaining: 10m 1s\n",
      "3300:\ttest: 0.8555513\tbest: 0.8555513 (3300)\ttotal: 11m 1s\tremaining: 9m 1s\n",
      "3600:\ttest: 0.8558157\tbest: 0.8558157 (3600)\ttotal: 12m 2s\tremaining: 8m 1s\n",
      "3900:\ttest: 0.8560490\tbest: 0.8560490 (3900)\ttotal: 13m 2s\tremaining: 7m\n",
      "4200:\ttest: 0.8562578\tbest: 0.8562578 (4200)\ttotal: 14m 3s\tremaining: 6m 1s\n",
      "4500:\ttest: 0.8563804\tbest: 0.8563804 (4500)\ttotal: 15m 3s\tremaining: 5m\n",
      "4800:\ttest: 0.8565982\tbest: 0.8566033 (4780)\ttotal: 16m 3s\tremaining: 4m\n",
      "5100:\ttest: 0.8567776\tbest: 0.8567776 (5100)\ttotal: 17m 3s\tremaining: 3m\n",
      "5400:\ttest: 0.8569610\tbest: 0.8569610 (5400)\ttotal: 18m 4s\tremaining: 2m\n",
      "5700:\ttest: 0.8571159\tbest: 0.8571261 (5695)\ttotal: 19m 4s\tremaining: 1m\n",
      "5999:\ttest: 0.8572577\tbest: 0.8572592 (5995)\ttotal: 20m 4s\tremaining: 0us\n",
      "bestTest = 0.8572592139\n",
      "bestIteration = 5995\n",
      "Shrink model to first 5996 iterations.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.843806\n",
      "[200]\tvalid_0's auc: 0.852688\n",
      "[300]\tvalid_0's auc: 0.855019\n",
      "[400]\tvalid_0's auc: 0.855864\n",
      "[500]\tvalid_0's auc: 0.856147\n",
      "[600]\tvalid_0's auc: 0.856411\n",
      "[700]\tvalid_0's auc: 0.856424\n",
      "[800]\tvalid_0's auc: 0.856442\n",
      "[900]\tvalid_0's auc: 0.856598\n",
      "[1000]\tvalid_0's auc: 0.856585\n",
      "Early stopping, best iteration is:\n",
      "[985]\tvalid_0's auc: 0.856663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6765360\tbest: 0.6765360 (0)\ttotal: 414ms\tremaining: 41m 26s\n",
      "300:\ttest: 0.8342060\tbest: 0.8342060 (300)\ttotal: 1m\tremaining: 18m 59s\n",
      "600:\ttest: 0.8383230\tbest: 0.8383230 (600)\ttotal: 1m 59s\tremaining: 17m 55s\n",
      "900:\ttest: 0.8397016\tbest: 0.8397016 (900)\ttotal: 3m\tremaining: 17m 3s\n",
      "1200:\ttest: 0.8409257\tbest: 0.8409257 (1200)\ttotal: 4m 1s\tremaining: 16m 6s\n",
      "1500:\ttest: 0.8420105\tbest: 0.8420105 (1500)\ttotal: 5m 1s\tremaining: 15m 3s\n",
      "1800:\ttest: 0.8428063\tbest: 0.8428063 (1800)\ttotal: 6m\tremaining: 13m 59s\n",
      "2100:\ttest: 0.8432276\tbest: 0.8432276 (2100)\ttotal: 7m\tremaining: 13m\n",
      "2400:\ttest: 0.8437664\tbest: 0.8437664 (2400)\ttotal: 8m 1s\tremaining: 12m 1s\n",
      "2700:\ttest: 0.8441136\tbest: 0.8441136 (2700)\ttotal: 9m 1s\tremaining: 11m 1s\n",
      "3000:\ttest: 0.8445557\tbest: 0.8445557 (3000)\ttotal: 9m 59s\tremaining: 9m 59s\n",
      "3300:\ttest: 0.8448339\tbest: 0.8448339 (3300)\ttotal: 10m 59s\tremaining: 8m 58s\n",
      "3600:\ttest: 0.8451937\tbest: 0.8452023 (3595)\ttotal: 12m\tremaining: 7m 59s\n",
      "3900:\ttest: 0.8454791\tbest: 0.8454845 (3885)\ttotal: 13m\tremaining: 6m 59s\n",
      "4200:\ttest: 0.8457343\tbest: 0.8457343 (4200)\ttotal: 14m 3s\tremaining: 6m 1s\n",
      "4500:\ttest: 0.8458529\tbest: 0.8458657 (4445)\ttotal: 14m 59s\tremaining: 4m 59s\n",
      "4800:\ttest: 0.8459715\tbest: 0.8459731 (4745)\ttotal: 15m 59s\tremaining: 3m 59s\n",
      "5100:\ttest: 0.8462025\tbest: 0.8462058 (5065)\ttotal: 16m 58s\tremaining: 2m 59s\n",
      "5400:\ttest: 0.8463536\tbest: 0.8463806 (5370)\ttotal: 17m 57s\tremaining: 1m 59s\n",
      "5700:\ttest: 0.8464957\tbest: 0.8465194 (5670)\ttotal: 18m 57s\tremaining: 59.6s\n",
      "5999:\ttest: 0.8466284\tbest: 0.8466335 (5980)\ttotal: 19m 57s\tremaining: 0us\n",
      "bestTest = 0.8466335237\n",
      "bestIteration = 5980\n",
      "Shrink model to first 5981 iterations.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.827267\n",
      "[200]\tvalid_0's auc: 0.838401\n",
      "[300]\tvalid_0's auc: 0.842603\n",
      "[400]\tvalid_0's auc: 0.845019\n",
      "[500]\tvalid_0's auc: 0.84639\n",
      "[600]\tvalid_0's auc: 0.847214\n",
      "[700]\tvalid_0's auc: 0.847657\n",
      "[800]\tvalid_0's auc: 0.847939\n",
      "[900]\tvalid_0's auc: 0.847961\n",
      "[1000]\tvalid_0's auc: 0.848162\n",
      "[1100]\tvalid_0's auc: 0.848326\n",
      "[1200]\tvalid_0's auc: 0.848419\n",
      "[1300]\tvalid_0's auc: 0.848497\n",
      "[1400]\tvalid_0's auc: 0.848683\n",
      "[1500]\tvalid_0's auc: 0.848844\n",
      "[1600]\tvalid_0's auc: 0.848877\n",
      "[1700]\tvalid_0's auc: 0.848915\n",
      "[1800]\tvalid_0's auc: 0.849032\n",
      "[1900]\tvalid_0's auc: 0.84907\n",
      "Early stopping, best iteration is:\n",
      "[1892]\tvalid_0's auc: 0.849097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6818588\tbest: 0.6818588 (0)\ttotal: 407ms\tremaining: 40m 40s\n",
      "300:\ttest: 0.8445651\tbest: 0.8445651 (300)\ttotal: 1m 2s\tremaining: 19m 43s\n",
      "600:\ttest: 0.8495462\tbest: 0.8495462 (600)\ttotal: 2m 3s\tremaining: 18m 26s\n",
      "900:\ttest: 0.8516886\tbest: 0.8516886 (900)\ttotal: 3m 4s\tremaining: 17m 22s\n",
      "1200:\ttest: 0.8531722\tbest: 0.8531722 (1200)\ttotal: 4m 3s\tremaining: 16m 12s\n",
      "1500:\ttest: 0.8540956\tbest: 0.8540956 (1500)\ttotal: 5m 3s\tremaining: 15m 8s\n",
      "1800:\ttest: 0.8549441\tbest: 0.8549441 (1800)\ttotal: 6m 2s\tremaining: 14m 4s\n",
      "2100:\ttest: 0.8555078\tbest: 0.8555078 (2100)\ttotal: 7m\tremaining: 13m\n",
      "2400:\ttest: 0.8561334\tbest: 0.8561334 (2400)\ttotal: 7m 59s\tremaining: 11m 58s\n",
      "2700:\ttest: 0.8566350\tbest: 0.8566350 (2700)\ttotal: 8m 58s\tremaining: 10m 57s\n",
      "3000:\ttest: 0.8569768\tbest: 0.8569768 (3000)\ttotal: 9m 57s\tremaining: 9m 57s\n",
      "3300:\ttest: 0.8573779\tbest: 0.8573779 (3300)\ttotal: 10m 56s\tremaining: 8m 57s\n",
      "3600:\ttest: 0.8576860\tbest: 0.8576872 (3595)\ttotal: 11m 56s\tremaining: 7m 57s\n",
      "3900:\ttest: 0.8580658\tbest: 0.8580658 (3900)\ttotal: 12m 57s\tremaining: 6m 58s\n",
      "4200:\ttest: 0.8582972\tbest: 0.8582972 (4200)\ttotal: 13m 57s\tremaining: 5m 58s\n",
      "4500:\ttest: 0.8585515\tbest: 0.8585515 (4500)\ttotal: 14m 57s\tremaining: 4m 58s\n",
      "4800:\ttest: 0.8587878\tbest: 0.8587878 (4800)\ttotal: 15m 56s\tremaining: 3m 58s\n",
      "5100:\ttest: 0.8589122\tbest: 0.8589122 (5100)\ttotal: 16m 56s\tremaining: 2m 59s\n",
      "5400:\ttest: 0.8590834\tbest: 0.8590834 (5400)\ttotal: 17m 56s\tremaining: 1m 59s\n",
      "5700:\ttest: 0.8592836\tbest: 0.8592836 (5700)\ttotal: 18m 56s\tremaining: 59.6s\n",
      "5999:\ttest: 0.8594107\tbest: 0.8594107 (5999)\ttotal: 19m 56s\tremaining: 0us\n",
      "bestTest = 0.859410733\n",
      "bestIteration = 5999\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.846578\n",
      "[200]\tvalid_0's auc: 0.854818\n",
      "[300]\tvalid_0's auc: 0.857803\n",
      "[400]\tvalid_0's auc: 0.858864\n",
      "[500]\tvalid_0's auc: 0.859528\n",
      "[600]\tvalid_0's auc: 0.859837\n",
      "[700]\tvalid_0's auc: 0.860128\n",
      "[800]\tvalid_0's auc: 0.860102\n",
      "Early stopping, best iteration is:\n",
      "[713]\tvalid_0's auc: 0.860202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6914641\tbest: 0.6914641 (0)\ttotal: 544ms\tremaining: 54m 25s\n",
      "300:\ttest: 0.8459468\tbest: 0.8459468 (300)\ttotal: 1m 2s\tremaining: 19m 45s\n",
      "600:\ttest: 0.8513044\tbest: 0.8513044 (600)\ttotal: 2m 3s\tremaining: 18m 26s\n",
      "900:\ttest: 0.8533852\tbest: 0.8533852 (900)\ttotal: 3m 3s\tremaining: 17m 17s\n",
      "1200:\ttest: 0.8547442\tbest: 0.8547442 (1200)\ttotal: 4m 3s\tremaining: 16m 14s\n",
      "1500:\ttest: 0.8557436\tbest: 0.8557436 (1500)\ttotal: 5m 3s\tremaining: 15m 10s\n",
      "1800:\ttest: 0.8565557\tbest: 0.8565557 (1800)\ttotal: 6m 5s\tremaining: 14m 11s\n",
      "2100:\ttest: 0.8571569\tbest: 0.8571597 (2095)\ttotal: 7m 7s\tremaining: 13m 12s\n",
      "2400:\ttest: 0.8575456\tbest: 0.8575456 (2400)\ttotal: 8m 7s\tremaining: 12m 10s\n",
      "2700:\ttest: 0.8579456\tbest: 0.8579460 (2695)\ttotal: 9m 8s\tremaining: 11m 9s\n",
      "3000:\ttest: 0.8584364\tbest: 0.8584364 (3000)\ttotal: 10m 8s\tremaining: 10m 7s\n",
      "3300:\ttest: 0.8587411\tbest: 0.8587411 (3300)\ttotal: 11m 8s\tremaining: 9m 6s\n",
      "3600:\ttest: 0.8590358\tbest: 0.8590358 (3600)\ttotal: 12m 8s\tremaining: 8m 5s\n",
      "3900:\ttest: 0.8592952\tbest: 0.8592952 (3900)\ttotal: 13m 8s\tremaining: 7m 4s\n",
      "4200:\ttest: 0.8594444\tbest: 0.8594491 (4180)\ttotal: 14m 7s\tremaining: 6m 2s\n",
      "4500:\ttest: 0.8596908\tbest: 0.8596908 (4500)\ttotal: 15m 6s\tremaining: 5m 2s\n",
      "4800:\ttest: 0.8599541\tbest: 0.8599545 (4775)\ttotal: 16m 7s\tremaining: 4m 1s\n",
      "5100:\ttest: 0.8600788\tbest: 0.8600918 (5090)\ttotal: 17m 8s\tremaining: 3m 1s\n",
      "5400:\ttest: 0.8601822\tbest: 0.8601860 (5395)\ttotal: 18m 9s\tremaining: 2m\n",
      "5700:\ttest: 0.8603401\tbest: 0.8603401 (5700)\ttotal: 19m 8s\tremaining: 1m\n",
      "5999:\ttest: 0.8604319\tbest: 0.8604319 (5999)\ttotal: 20m 7s\tremaining: 0us\n",
      "bestTest = 0.8604318798\n",
      "bestIteration = 5999\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.83938\n",
      "[200]\tvalid_0's auc: 0.851101\n",
      "[300]\tvalid_0's auc: 0.855827\n",
      "[400]\tvalid_0's auc: 0.858429\n",
      "[500]\tvalid_0's auc: 0.859705\n",
      "[600]\tvalid_0's auc: 0.860437\n",
      "[700]\tvalid_0's auc: 0.860756\n",
      "[800]\tvalid_0's auc: 0.861166\n",
      "[900]\tvalid_0's auc: 0.861412\n",
      "[1000]\tvalid_0's auc: 0.861557\n",
      "[1100]\tvalid_0's auc: 0.861823\n",
      "[1200]\tvalid_0's auc: 0.861829\n",
      "[1300]\tvalid_0's auc: 0.861916\n",
      "[1400]\tvalid_0's auc: 0.862005\n",
      "Early stopping, best iteration is:\n",
      "[1398]\tvalid_0's auc: 0.862014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6636217\tbest: 0.6636217 (0)\ttotal: 518ms\tremaining: 51m 47s\n",
      "300:\ttest: 0.8486139\tbest: 0.8486139 (300)\ttotal: 1m\tremaining: 19m 5s\n",
      "600:\ttest: 0.8537899\tbest: 0.8537899 (600)\ttotal: 2m 1s\tremaining: 18m 6s\n",
      "900:\ttest: 0.8556963\tbest: 0.8556963 (900)\ttotal: 3m 2s\tremaining: 17m 11s\n",
      "1200:\ttest: 0.8570461\tbest: 0.8570461 (1200)\ttotal: 4m 1s\tremaining: 16m 6s\n",
      "1500:\ttest: 0.8580706\tbest: 0.8580706 (1500)\ttotal: 5m 1s\tremaining: 15m 3s\n",
      "1800:\ttest: 0.8587388\tbest: 0.8587388 (1800)\ttotal: 6m 2s\tremaining: 14m 4s\n",
      "2100:\ttest: 0.8593062\tbest: 0.8593062 (2100)\ttotal: 7m 2s\tremaining: 13m 3s\n",
      "2400:\ttest: 0.8598994\tbest: 0.8598994 (2400)\ttotal: 8m\tremaining: 12m\n",
      "2700:\ttest: 0.8602836\tbest: 0.8602836 (2700)\ttotal: 8m 59s\tremaining: 10m 58s\n",
      "3000:\ttest: 0.8605787\tbest: 0.8605787 (3000)\ttotal: 9m 57s\tremaining: 9m 56s\n",
      "3300:\ttest: 0.8608863\tbest: 0.8608863 (3300)\ttotal: 10m 55s\tremaining: 8m 55s\n",
      "3600:\ttest: 0.8612337\tbest: 0.8612337 (3600)\ttotal: 11m 53s\tremaining: 7m 55s\n",
      "3900:\ttest: 0.8614522\tbest: 0.8614557 (3865)\ttotal: 12m 54s\tremaining: 6m 56s\n",
      "4200:\ttest: 0.8616426\tbest: 0.8616426 (4200)\ttotal: 13m 54s\tremaining: 5m 57s\n",
      "4500:\ttest: 0.8617719\tbest: 0.8617724 (4495)\ttotal: 14m 55s\tremaining: 4m 58s\n",
      "4800:\ttest: 0.8619241\tbest: 0.8619241 (4800)\ttotal: 15m 54s\tremaining: 3m 58s\n",
      "5100:\ttest: 0.8620946\tbest: 0.8620969 (5085)\ttotal: 16m 54s\tremaining: 2m 58s\n",
      "5400:\ttest: 0.8623087\tbest: 0.8623188 (5390)\ttotal: 17m 54s\tremaining: 1m 59s\n",
      "5700:\ttest: 0.8624286\tbest: 0.8624286 (5700)\ttotal: 18m 54s\tremaining: 59.5s\n",
      "5999:\ttest: 0.8625049\tbest: 0.8625147 (5955)\ttotal: 19m 53s\tremaining: 0us\n",
      "bestTest = 0.8625146747\n",
      "bestIteration = 5955\n",
      "Shrink model to first 5956 iterations.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.851134\n",
      "[200]\tvalid_0's auc: 0.859054\n",
      "[300]\tvalid_0's auc: 0.86136\n",
      "[400]\tvalid_0's auc: 0.862382\n",
      "[500]\tvalid_0's auc: 0.862782\n",
      "[600]\tvalid_0's auc: 0.863009\n",
      "[700]\tvalid_0's auc: 0.86305\n",
      "Early stopping, best iteration is:\n",
      "[653]\tvalid_0's auc: 0.863104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6653582\tbest: 0.6653582 (0)\ttotal: 468ms\tremaining: 46m 48s\n",
      "300:\ttest: 0.8448931\tbest: 0.8448931 (300)\ttotal: 1m 2s\tremaining: 19m 42s\n",
      "600:\ttest: 0.8504478\tbest: 0.8504478 (600)\ttotal: 2m 3s\tremaining: 18m 25s\n",
      "900:\ttest: 0.8527124\tbest: 0.8527124 (900)\ttotal: 3m 2s\tremaining: 17m 14s\n",
      "1200:\ttest: 0.8540191\tbest: 0.8540191 (1200)\ttotal: 4m 2s\tremaining: 16m 8s\n",
      "1500:\ttest: 0.8551530\tbest: 0.8551530 (1500)\ttotal: 5m\tremaining: 15m 1s\n",
      "1800:\ttest: 0.8560977\tbest: 0.8560977 (1800)\ttotal: 6m\tremaining: 14m\n",
      "2100:\ttest: 0.8567510\tbest: 0.8567510 (2100)\ttotal: 6m 59s\tremaining: 12m 58s\n",
      "2400:\ttest: 0.8574413\tbest: 0.8574413 (2400)\ttotal: 7m 58s\tremaining: 11m 57s\n",
      "2700:\ttest: 0.8577887\tbest: 0.8577887 (2700)\ttotal: 8m 58s\tremaining: 10m 57s\n",
      "3000:\ttest: 0.8581604\tbest: 0.8581604 (3000)\ttotal: 9m 56s\tremaining: 9m 56s\n",
      "3300:\ttest: 0.8585659\tbest: 0.8585659 (3300)\ttotal: 10m 56s\tremaining: 8m 57s\n",
      "3600:\ttest: 0.8588911\tbest: 0.8588911 (3600)\ttotal: 11m 56s\tremaining: 7m 57s\n",
      "3900:\ttest: 0.8591538\tbest: 0.8591538 (3900)\ttotal: 12m 54s\tremaining: 6m 56s\n",
      "4200:\ttest: 0.8594365\tbest: 0.8594367 (4190)\ttotal: 13m 54s\tremaining: 5m 57s\n",
      "4500:\ttest: 0.8595774\tbest: 0.8595774 (4500)\ttotal: 14m 54s\tremaining: 4m 57s\n",
      "4800:\ttest: 0.8597021\tbest: 0.8597023 (4795)\ttotal: 15m 53s\tremaining: 3m 58s\n",
      "5100:\ttest: 0.8598894\tbest: 0.8599046 (5095)\ttotal: 16m 52s\tremaining: 2m 58s\n",
      "5400:\ttest: 0.8601257\tbest: 0.8601257 (5400)\ttotal: 17m 50s\tremaining: 1m 58s\n",
      "5700:\ttest: 0.8602282\tbest: 0.8602283 (5660)\ttotal: 18m 49s\tremaining: 59.3s\n",
      "5999:\ttest: 0.8603144\tbest: 0.8603151 (5990)\ttotal: 19m 48s\tremaining: 0us\n",
      "bestTest = 0.8603150845\n",
      "bestIteration = 5990\n",
      "Shrink model to first 5991 iterations.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.837547\n",
      "[200]\tvalid_0's auc: 0.84924\n",
      "[300]\tvalid_0's auc: 0.85368\n",
      "[400]\tvalid_0's auc: 0.856172\n",
      "[500]\tvalid_0's auc: 0.857961\n",
      "[600]\tvalid_0's auc: 0.858802\n",
      "[700]\tvalid_0's auc: 0.859278\n",
      "[800]\tvalid_0's auc: 0.859696\n",
      "[900]\tvalid_0's auc: 0.860086\n",
      "[1000]\tvalid_0's auc: 0.86019\n",
      "[1100]\tvalid_0's auc: 0.860482\n",
      "[1200]\tvalid_0's auc: 0.860548\n",
      "[1300]\tvalid_0's auc: 0.860703\n",
      "[1400]\tvalid_0's auc: 0.860701\n",
      "[1500]\tvalid_0's auc: 0.86076\n",
      "Early stopping, best iteration is:\n",
      "[1426]\tvalid_0's auc: 0.860824\n",
      "\n",
      "CV AUC scores for CatBoost: [0.8643163394849895, 0.8529282569491268, 0.8572591770790834, 0.8466335293466866, 0.8594107134230689, 0.8604318559842681, 0.8625146701564653, 0.8603150525999352]\n",
      "Maximum CV AUC score for Catboost: 0.8643163394849895\n",
      "\n",
      "CV AUC scores for LGBM: [0.8640839131794593, 0.8536983340327734, 0.8566631020954913, 0.8490967761253121, 0.860201858815083, 0.8620135587009569, 0.8631037402752447, 0.8608242026462625]\n",
      "Maximum CV AUC score for LGBM: 0.8640839131794593\n",
      "\n",
      "CB CV Score Results\n",
      "CV AUC scores:  [0.8643163394849895, 0.8529282569491268, 0.8572591770790834, 0.8466335293466866, 0.8594107134230689, 0.8604318559842681, 0.8625146701564653, 0.8603150525999352]\n",
      "Maximum CV AUC score:  0.8643163394849895\n",
      "Average CV AUC score:  0.857976199377953\n",
      "Std CV AUC score:  0.005350296896808902\n",
      "LGB CV Score Results\n",
      "CV AUC scores:  [0.8640839131794593, 0.8536983340327734, 0.8566631020954913, 0.8490967761253121, 0.860201858815083, 0.8620135587009569, 0.8631037402752447, 0.8608242026462625]\n",
      "Maximum CV AUC score:  0.8640839131794593\n",
      "Average CV AUC score:  0.8587106857338229\n",
      "Std CV AUC score:  0.004841404088853098\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop(columns=[\"target\", \"case_id\", \"week_num\"])\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "weeks = df_train[\"week_num\"]\n",
    "\n",
    "# Delete df_train to save memory space\n",
    "del df_train\n",
    "gc.collect()\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits = 8, shuffle = False)\n",
    "\n",
    "# Parameters for lightgbm\n",
    "params1 = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"colsample_bynode\": 0.8, # rate of randomly select a subset of features on each tree node\n",
    "    \"colsample_bytree\": 0.8, # rate of randomly select a subset of features on each iteration (tree)\n",
    "    \"extra_trees\": True, # use extremely randomized trees, if set to true, when evaluating node splits LightGBM will check only one randomly-chosen threshold for each feature\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"l1_regularization\": 0.1,\n",
    "    \"l2_regularization\": 10,\n",
    "    \"max_depth\": 20,\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_estimators\": 2000,\n",
    "    \"num_leaves\": 64, # max number of leaves in one tree\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1, # controls the level of LightGBM’s verbosity - < 0: Fatal, = 0: Error (Warning), = 1: Info, > 1: Debug\n",
    "}\n",
    "\n",
    "# Parameters for lightgbm2\n",
    "params2 = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"extra_trees\": True,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"l1_regularization\": 0.1,\n",
    "    \"l2_regularization\": 10,\n",
    "    \"max_depth\": 16,\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_estimators\": 2000,\n",
    "    \"num_leaves\": 72,\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "# Initialize lists to save models and cross validation scores\n",
    "fitted_models_cat = []\n",
    "fitted_models_lgb = []\n",
    "\n",
    "cv_scores_cat = []\n",
    "cv_scores_lgb = []\n",
    "\n",
    "# This method is borrowed from some other public notebook:\n",
    "# In addition to training by catboost, train two lightgbms for odd and even cross validations, respectively.\n",
    "# Initially, this works well for test data of public leaderboard, but might also be the reason that is overfitting the public leadboard data.\n",
    "iter_cnt = 0\n",
    "for idx_train, idx_valid in cv.split(X, y, groups = weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features = cat_cols)\n",
    "    val_pool = Pool(X_valid, y_valid, cat_features = cat_cols)\n",
    "\n",
    "    clf = CatBoostClassifier(\n",
    "        best_model_min_trees = 1200, # The minimal number of trees that the best model should have. If set, the output model contains at least the given number of trees even if the best model is located within these trees.\n",
    "        boosting_type = \"Plain\", # \"Plain\" is the classic gradient boosting scheme\n",
    "        eval_metric = \"AUC\",\n",
    "        iterations = 6000,\n",
    "        learning_rate = 0.05,\n",
    "        l2_leaf_reg = 10, # Coefficient at the L2 regularization term of the cost function.\n",
    "        max_leaves = 64,\n",
    "        random_seed = 42,\n",
    "        task_type = \"GPU\",\n",
    "        use_best_model = True # Use the validation dataset to identify the iteration with the optimal value of the metric specified, no trees are saved after this iteration.\n",
    "    )\n",
    "\n",
    "    clf.fit(train_pool, eval_set = val_pool, verbose = 300)\n",
    "    fitted_models_cat.append(clf)\n",
    "\n",
    "    y_pred_valid = clf.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_cat.append(auc_score)\n",
    "\n",
    "    X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "    X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n",
    "\n",
    "    if iter_cnt % 2 == 0:\n",
    "        model = lgb.LGBMClassifier(**params1)\n",
    "    else:\n",
    "        model = lgb.LGBMClassifier(**params2)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        # log_evaulation: The period to log the evaluation results.\n",
    "        # early_stopping: Validation score needs to improve at least every (stopping_rounds) rounds to continue training\n",
    "        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)],\n",
    "    )\n",
    "    fitted_models_lgb.append(model)\n",
    "\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_lgb.append(auc_score)\n",
    "\n",
    "    iter_cnt += 1\n",
    "\n",
    "ensemble_model = VotingModel(fitted_models_cat + fitted_models_lgb)\n",
    "\n",
    "print(f\"\\nCV AUC scores for CatBoost: {cv_scores_cat}\")\n",
    "print(f\"Maximum CV AUC score for Catboost: {max(cv_scores_cat)}\", end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"CV AUC scores for LGBM: {cv_scores_lgb}\")\n",
    "print(f\"Maximum CV AUC score for LGBM: {max(cv_scores_lgb)}\", end=\"\\n\\n\")\n",
    "\n",
    "print('CB CV Score Results')    \n",
    "print(\"CV AUC scores: \", cv_scores_cat)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores_cat))\n",
    "print(\"Average CV AUC score: \", np.mean(cv_scores_cat))\n",
    "print(\"Std CV AUC score: \", np.std(cv_scores_cat))\n",
    "\n",
    "print('LGB CV Score Results')\n",
    "print(\"CV AUC scores: \", cv_scores_lgb)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores_lgb))\n",
    "print(\"Average CV AUC score: \", np.mean(cv_scores_lgb))\n",
    "print(\"Std CV AUC score: \", np.std(cv_scores_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ensemble model\n",
    "\n",
    "# ensemble_model = VotingModel(fitted_models_cat + fitted_models_lgb)\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(ensemble_model, open('ensemble_model_' + 'sv' + VERSION + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ensemble model to save memory and time\n",
    "\n",
    "import pickle\n",
    "ensemble_model = pickle.load(open(PERSONAL_PATH + 'ensemble_model_' + 'sv' + VERSION +'.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingModel(estimators=[&lt;catboost.core.CatBoostClassifier object at 0x000002D2C259FBD0&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D2C2591310&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D20565F7D0&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D2070CBA50&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D20AA63CD0&gt;,\n",
       "                        &lt;catboost.core.CatBoo...\n",
       "                                       l2_regularization=10, learning_rate=0.05,\n",
       "                                       max_depth=20, metric=&#x27;auc&#x27;,\n",
       "                                       n_estimators=2000, num_leaves=64,\n",
       "                                       objective=&#x27;binary&#x27;, random_state=42,\n",
       "                                       verbose=-1),\n",
       "                        LGBMClassifier(colsample_bynode=0.8,\n",
       "                                       colsample_bytree=0.8, extra_trees=True,\n",
       "                                       l1_regularization=0.1,\n",
       "                                       l2_regularization=10, learning_rate=0.03,\n",
       "                                       max_depth=16, metric=&#x27;auc&#x27;,\n",
       "                                       n_estimators=2000, num_leaves=72,\n",
       "                                       objective=&#x27;binary&#x27;, random_state=42,\n",
       "                                       verbose=-1)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingModel</label><div class=\"sk-toggleable__content\"><pre>VotingModel(estimators=[&lt;catboost.core.CatBoostClassifier object at 0x000002D2C259FBD0&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D2C2591310&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D20565F7D0&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D2070CBA50&gt;,\n",
       "                        &lt;catboost.core.CatBoostClassifier object at 0x000002D20AA63CD0&gt;,\n",
       "                        &lt;catboost.core.CatBoo...\n",
       "                                       l2_regularization=10, learning_rate=0.05,\n",
       "                                       max_depth=20, metric=&#x27;auc&#x27;,\n",
       "                                       n_estimators=2000, num_leaves=64,\n",
       "                                       objective=&#x27;binary&#x27;, random_state=42,\n",
       "                                       verbose=-1),\n",
       "                        LGBMClassifier(colsample_bynode=0.8,\n",
       "                                       colsample_bytree=0.8, extra_trees=True,\n",
       "                                       l1_regularization=0.1,\n",
       "                                       l2_regularization=10, learning_rate=0.03,\n",
       "                                       max_depth=16, metric=&#x27;auc&#x27;,\n",
       "                                       n_estimators=2000, num_leaves=72,\n",
       "                                       objective=&#x27;binary&#x27;, random_state=42,\n",
       "                                       verbose=-1)])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingModel(estimators=[<catboost.core.CatBoostClassifier object at 0x000002D2C259FBD0>,\n",
       "                        <catboost.core.CatBoostClassifier object at 0x000002D2C2591310>,\n",
       "                        <catboost.core.CatBoostClassifier object at 0x000002D20565F7D0>,\n",
       "                        <catboost.core.CatBoostClassifier object at 0x000002D2070CBA50>,\n",
       "                        <catboost.core.CatBoostClassifier object at 0x000002D20AA63CD0>,\n",
       "                        <catboost.core.CatBoo...\n",
       "                                       l2_regularization=10, learning_rate=0.05,\n",
       "                                       max_depth=20, metric='auc',\n",
       "                                       n_estimators=2000, num_leaves=64,\n",
       "                                       objective='binary', random_state=42,\n",
       "                                       verbose=-1),\n",
       "                        LGBMClassifier(colsample_bynode=0.8,\n",
       "                                       colsample_bytree=0.8, extra_trees=True,\n",
       "                                       l1_regularization=0.1,\n",
       "                                       l2_regularization=10, learning_rate=0.03,\n",
       "                                       max_depth=16, metric='auc',\n",
       "                                       n_estimators=2000, num_leaves=72,\n",
       "                                       objective='binary', random_state=42,\n",
       "                                       verbose=-1)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample submission data (only 10 records, use for Kaggle submission)\n",
    "\n",
    "df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n",
    "df_subm = df_subm.set_index(\"case_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process\n",
    "\n",
    "X_test = df_test.drop(columns=[\"week_num\"]).set_index(\"case_id\")\n",
    "X_test[cat_cols] = X_test[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57543</th>\n",
       "      <td>0.008518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57549</th>\n",
       "      <td>0.044705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57551</th>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57552</th>\n",
       "      <td>0.017779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57569</th>\n",
       "      <td>0.162139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57630</th>\n",
       "      <td>0.009587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57631</th>\n",
       "      <td>0.034756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57632</th>\n",
       "      <td>0.007646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>0.039108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57634</th>\n",
       "      <td>0.030771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "case_id          \n",
       "57543    0.008518\n",
       "57549    0.044705\n",
       "57551    0.002777\n",
       "57552    0.017779\n",
       "57569    0.162139\n",
       "57630    0.009587\n",
       "57631    0.034756\n",
       "57632    0.007646\n",
       "57633    0.039108\n",
       "57634    0.030771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred: pd.Series = pd.Series(ensemble_model.predict_proba(X_test)[:, 1], index = X_test.index)\n",
    "\n",
    "df_subm[\"score\"] = y_pred\n",
    "\n",
    "display(df_subm)\n",
    "\n",
    "# df_subm.to_csv(\"submission.csv\")\n",
    "\n",
    "# del X_test, y_pred, df_subm\n",
    "# gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
